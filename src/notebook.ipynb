{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08spB7MyafSN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "encoder_path = '../models/encoder'\n",
        "decoder_path = '../models/decoder'\n",
        "autoencoder_path = '../models/autoencoder'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and process the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0nvq7A9afSR",
        "outputId": "37539bd8-1101-40f2-f78a-4b795f390752"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "# Build a Validation dataset from both testing and training images\n",
        "(val_images, val_labels) = (np.concatenate((train_images[0:5000], test_images[0:5000])), np.concatenate((train_labels[0:5000], test_labels[0:5000])))\n",
        "# Build the Testing and Training dataset\n",
        "(train_images, train_labels) = (train_images[5000:], train_labels[5000:])\n",
        "(test_images, test_labels) = (test_images[5000:], test_labels[5000:])\n",
        "# Add a (naive) variation parameter in the targets\n",
        "def add_var_parameter(dataset):\n",
        "  ohe = np.zeros((dataset.shape[0], 10)) # The one-hot encoding version of the target\n",
        "  var = np.zeros((dataset.shape[0], 1)) # The variation parameter\n",
        "  for i in range(dataset.shape[0]):\n",
        "    ohe[i, dataset[i]] = 1\n",
        "    var[i] = i/dataset.shape[0]\n",
        "  return ohe, var\n",
        "# Do for each dataset\n",
        "train_ohe, train_var = add_var_parameter(train_labels)\n",
        "val_ohe, val_var = add_var_parameter(val_labels)\n",
        "test_ohe, test_var = add_var_parameter(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZoDx0G4afST",
        "outputId": "a9a5f3a6-dcdf-4968-e005-e558fa883b83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input (InputLayer)              [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Layer1_nt_ (Conv2D)             (None, 28, 28, 64)   640         Input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "Layer2_nt_ (MaxPooling2D)       (None, 14, 14, 64)   0           Layer1_nt_[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Layer3_nt_ (BatchNormalization) (None, 14, 14, 64)   256         Layer2_nt_[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Layer4_nt_ (Conv2D)             (None, 14, 14, 96)   55392       Layer3_nt_[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Layer5_nt_ (BatchNormalization) (None, 14, 14, 96)   384         Layer4_nt_[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Layer6_nt_ (MaxPooling2D)       (None, 7, 7, 96)     0           Layer5_nt_[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Layer7_nt_ (Conv2D)             (None, 7, 7, 128)    110720      Layer6_nt_[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Layer8_nt_ (BatchNormalization) (None, 7, 7, 128)    512         Layer7_nt_[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Layer9 (Flatten)                (None, 6272)         0           Layer8_nt_[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Layer10 (LayerNormalization)    (None, 6272)         12544       Layer9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Layer11 (Dense)                 (None, 128)          802944      Layer10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Output1_nt_ (Dense)             (None, 10)           62730       Layer9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Output2 (Dense)                 (None, 1)            129         Layer11[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,046,251\n",
            "Trainable params: 1,045,675\n",
            "Non-trainable params: 576\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_input = layers.Input(shape = (28, 28, 1), name='Input')\n",
        "x = layers.Conv2D(64, (3, 3), activation='sigmoid', padding='same', name='Layer1_nt_')(encoder_input)\n",
        "x = layers.MaxPool2D((2, 2), name='Layer2_nt_')(x)\n",
        "x = layers.BatchNormalization(name='Layer3_nt_')(x)\n",
        "x = layers.Conv2D(96, (3, 3), activation='sigmoid', padding='same', name='Layer4_nt_')(x)\n",
        "x = layers.BatchNormalization(name='Layer5_nt_')(x)\n",
        "x = layers.MaxPool2D((2, 2), name='Layer6_nt_')(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='sigmoid', padding='same', name='Layer7_nt_')(x)\n",
        "x = layers.BatchNormalization(name='Layer8_nt_')(x)\n",
        "x = layers.Flatten(name='Layer9')(x)\n",
        "encoder_out1 = layers.Dense(10, activation='softmax', name='Output1_nt_')(x)\n",
        "x = layers.LayerNormalization(name='Layer10')(x)\n",
        "x = layers.Dense(128, activation='sigmoid', name='Layer11')(x)\n",
        "encoder_out2 = layers.Dense(1, activation='sigmoid', name='Output2')(x)\n",
        "encoder = models.Model(inputs=encoder_input, outputs=[encoder_out1, encoder_out2])\n",
        "tf.keras.utils.plot_model(encoder, show_shapes=True, to_file='../models/encoder.png')\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xieRMiP-afSU",
        "outputId": "33dbee54-2a1a-47ca-e133-f3bc7f91fe50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input2 (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Layer1 (Dense)                  (None, 128)          256         Input2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Input1 (InputLayer)             [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Layer2 (LayerNormalization)     (None, 128)          256         Layer1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Layer3 (Concatenate)            (None, 138)          0           Input1[0][0]                     \n",
            "                                                                 Layer2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Layer4 (Dense)                  (None, 6272)         871808      Layer3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Layer5 (Reshape)                (None, 7, 7, 128)    0           Layer4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Layer6 (BatchNormalization)     (None, 7, 7, 128)    512         Layer5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Layer7 (Conv2D)                 (None, 7, 7, 128)    147584      Layer6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Layer8 (BatchNormalization)     (None, 7, 7, 128)    512         Layer7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Layer9 (Conv2D)                 (None, 7, 7, 96)     110688      Layer8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Layer10 (BatchNormalization)    (None, 7, 7, 96)     384         Layer9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Layer11 (UpSampling2D)          (None, 14, 14, 96)   0           Layer10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Layer12 (Conv2D)                (None, 14, 14, 64)   55360       Layer11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Layer13 (BatchNormalization)    (None, 14, 14, 64)   256         Layer12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Layer14 (UpSampling2D)          (None, 28, 28, 64)   0           Layer13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Layer15 (Conv2D)                (None, 28, 28, 1)    577         Layer14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Output (Reshape)                (None, 28, 28)       0           Layer15[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,188,193\n",
            "Trainable params: 1,187,361\n",
            "Non-trainable params: 832\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "decoder_input1 = layers.Input(shape = (10,), name='Input1')\n",
        "decoder_input2 = layers.Input(shape = (1,), name='Input2')\n",
        "x = layers.Dense(128, activation='sigmoid', name='Layer1')(decoder_input2)\n",
        "x = layers.LayerNormalization(name='Layer2')(x)\n",
        "x = layers.Concatenate(axis=1, name='Layer3')([decoder_input1, x])\n",
        "x = layers.Dense(6272, activation='sigmoid', name='Layer4')(x)\n",
        "x = layers.Reshape((7, 7, 128), name='Layer5')(x)\n",
        "x = layers.BatchNormalization(name='Layer6')(x)\n",
        "x = layers.Conv2D(128, (3, 3), activation='sigmoid', padding='same', name='Layer7')(x)\n",
        "x = layers.BatchNormalization(name='Layer8')(x)\n",
        "x = layers.Conv2D(96, (3, 3), activation='sigmoid', padding='same', name='Layer9')(x)\n",
        "x = layers.BatchNormalization(name='Layer10')(x)\n",
        "x = layers.UpSampling2D((2, 2), name='Layer11')(x)\n",
        "x = layers.Conv2D(64, (3, 3), activation='sigmoid', padding='same', name='Layer12')(x)\n",
        "x = layers.BatchNormalization(name='Layer13')(x)\n",
        "x = layers.UpSampling2D((2, 2), name='Layer14')(x)\n",
        "x = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='Layer15')(x)\n",
        "x = layers.Reshape((28, 28), name='Output')(x)\n",
        "decoder = models.Model(inputs=[decoder_input1, decoder_input2], outputs=x)\n",
        "tf.keras.utils.plot_model(decoder, show_shapes=True, to_file='../models/decoder.png')\n",
        "decoder.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 28, 28)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_11 (Functional)           [(None, 10), (None,  1046251     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_12 (Functional)           (None, 28, 28)       1188193     model_11[0][0]                   \n",
            "                                                                 model_11[0][1]                   \n",
            "==================================================================================================\n",
            "Total params: 2,234,444\n",
            "Trainable params: 2,233,036\n",
            "Non-trainable params: 1,408\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "ae_input = layers.Input(shape = (28, 28))\n",
        "latent_vector = encoder(ae_input)\n",
        "ae_output = decoder(latent_vector)\n",
        "autoencoder = models.Model(inputs = ae_input , outputs = ae_output)\n",
        "tf.keras.utils.plot_model(autoencoder, show_shapes=True, to_file='../models/autoencoder.png')\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training the encoder - classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOVmKg-rjUB_",
        "outputId": "1f54ec12-eee4-427f-8cb6-31536290a4d9"
      },
      "outputs": [],
      "source": [
        "# Create a dummy loss for the first training - we don't care about the variation parameter for now\n",
        "def dum_loss(y_true, y_pred):\n",
        "  return 0\n",
        "\n",
        "# Compile the encoder\n",
        "encoder.compile(optimizer=optimizers.SGD(learning_rate=0.01, momentum=0.9), loss = {'Output1_nt_': 'categorical_crossentropy', 'Output2': dum_loss}, metrics=['acc'])\n",
        "# Train it with the training set example and encoded labels\n",
        "encoder.fit(train_images, [train_ohe, train_var], epochs=3, validation_data=(val_images, [val_ohe, val_var]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzQBmXYLXH35",
        "outputId": "c1a80100-23a1-4c2c-94ce-3928050d4da5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed weights for Layer1_nt_\n",
            "Fixed weights for Layer2_nt_\n",
            "Fixed weights for Layer3_nt_\n",
            "Fixed weights for Layer4_nt_\n",
            "Fixed weights for Layer5_nt_\n",
            "Fixed weights for Layer6_nt_\n",
            "Fixed weights for Layer7_nt_\n",
            "Fixed weights for Layer8_nt_\n",
            "Fixed weights for Output1_nt_\n"
          ]
        }
      ],
      "source": [
        "# Fix encoder weights that correspond to the classifier part\n",
        "for layer in encoder.layers:\n",
        "  if '_nt_' in layer.name:\n",
        "    layer.trainable = False\n",
        "    print('Fixed weights for {}'.format(layer.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pre-training the decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIbpqSU1modh",
        "outputId": "7022c05c-fa33-41b5-d8ce-84fd11a1e02a"
      },
      "outputs": [],
      "source": [
        "# Compile the decoder\n",
        "decoder.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss = \"binary_crossentropy\")\n",
        "# For performance purposes, we train the decoder a few iterations so that the weights are already initialized in a good way\n",
        "# We train it giving the target in input and the image matrix in output\n",
        "decoder.fit([train_ohe, train_var], train_images, batch_size=512, epochs=15, validation_data=([val_ohe, val_var], val_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training the whole autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gtdyun2GafSU",
        "outputId": "641eb89b-48ab-42c8-92f5-e8f507e638e0"
      },
      "outputs": [],
      "source": [
        "def random_decode():\n",
        "  ohe = np.zeros((1, 10)) # One hot encoded vector init\n",
        "  ohe[0, np.random.random_integers(0, 9)] = 1 # Random number\n",
        "  var = np.zeros((1, 1)) # Variation parameter init\n",
        "  var[0] = np.random.random_integers(0, 100)/100 # Random ratio\n",
        "  image = decoder.predict([ohe, var])[0]\n",
        "  plt.rcParams[\"figure.figsize\"] = (1,1)\n",
        "  plt.imshow(image, cmap = \"gray\")\n",
        "  plt.show()\n",
        "# Compile the autoencoder\n",
        "autoencoder.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss = \"binary_crossentropy\")\n",
        "# Train the whole autoencoder\n",
        "for i in range(25):\n",
        "  random_decode()\n",
        "  # We train one iteration by one to see the changes\n",
        "  autoencoder.fit(train_images, train_images, batch_size=128, epochs=1, validation_data=[val_images, val_images])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving the model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbV2FMsmP29o",
        "outputId": "04f04a47-4876-42c9-e3c4-b103dd35d854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: drive/My Drive/IIT/CV/P2V2/models/encoder/assets\n"
          ]
        }
      ],
      "source": [
        "encoder.save(encoder_path)\n",
        "decoder.save(decoder_path)\n",
        "autoencoder.save(autoencoder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQtubMUPQJ5y"
      },
      "outputs": [],
      "source": [
        "encoder = tf.keras.models.load_model(encoder_path, custom_objects={'dum_loss': dum_loss})\n",
        "decoder = tf.keras.models.load_model(decoder_path)\n",
        "autoencoder = tf.keras.models.load_model(autoencoder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VIDEO - Transitions from number to number for multiple variations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {
        "id": "CFBuRZ29U1sH"
      },
      "outputs": [],
      "source": [
        "# 1. Generate the frames\n",
        "frames = 60 # Number of frames per number\n",
        "col = 32 # Number of variations (vertically)\n",
        "row = 32 # Number of variations (horizontally)\n",
        "nb_of_var = col*row # Total number of variations\n",
        "# Initialize the input vectors\n",
        "images_ohe = np.zeros((frames*10*nb_of_var, 10)) # 'One hot encoding' vectors\n",
        "images_var = np.zeros((frames*10*nb_of_var, 1)) # Variation vector\n",
        "\n",
        "for i in range(images_var.shape[0]):\n",
        "  images_var[i] = (i/nb_of_var)%1 # For each frame, compute the variation parameter (from 0 (top left corner) to 1 (bottom right corner))\n",
        "\n",
        "for n in range(10): # For each number\n",
        "  for i in range(frames): # For each frame per number\n",
        "    for v in range(nb_of_var): # For each variation\n",
        "      progress = i/frames # Compute the progress of the transition\n",
        "      progress = (np.tanh(10*(progress-0.5))+1)/2 # Curve the progress (ease in - ease out)\n",
        "      image_i = (n*frames+i)*nb_of_var + v # Compute the index of the frame\n",
        "      images_ohe[image_i, n%10] = 1 - progress # Add the value for the current number in the OHE vector of the frame\n",
        "      images_ohe[image_i, (n+1)%10] = progress # Add the value for the next number in the OHE vector of the frame\n",
        "\n",
        "images = decoder.predict([images_ohe, images_var]) # Decode each frame with the decoder\n",
        "images = images.reshape((frames*10, row, col, 28, 28)) # Reshape the images matrix\n",
        "\n",
        "# 2. Create the video\n",
        "video_name = 'results/Number2Number.mp4' # Video path\n",
        "video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), 25, (28*row,28*col))\n",
        "for f in range(images.shape[0]): # For each frame\n",
        "  im = np.zeros((28*row, 28*col, 3)) # Create a zero matrix\n",
        "  for r in range(images.shape[1]): # For each row\n",
        "    for c in range(images.shape[2]): # For each column\n",
        "      # Draw the image in the matrix\n",
        "      im[r*28:r*28+28,c*28:c*28+28, 0] = images[f, r, c]*255\n",
        "      im[r*28:r*28+28,c*28:c*28+28, 1] = images[f, r, c]*255\n",
        "      im[r*28:r*28+28,c*28:c*28+28, 2] = images[f, r, c]*255\n",
        "  # Write the frame in the video\n",
        "  video.write(im.astype('uint8'))\n",
        "# Save the video\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VIDEO - Transitions from number to random number along with continuous variation changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9RgK2ZK4BUW",
        "outputId": "5475df6f-e6b4-43f8-8ac4-e6661566205a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: This function is deprecated. Please call randint(0, 9 + 1) instead\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ],
      "source": [
        "# 1. Generate frames\n",
        "number_transition_frames = 60 # Number of frame for each number transition\n",
        "variation_transition_frames = 250 # Number of frame for a whole variation transition (from 0 to 1 - or 1 to 0)\n",
        "number_transitions = 64 # Number of transitions to complete\n",
        "total_frames = (number_transition_frames)*number_transitions # Compute the total number of frames\n",
        "images_ohe = np.zeros((total_frames, 10)) # 'One hot encoding' vectors\n",
        "images_var = np.zeros((total_frames, 1)) # Variation vector\n",
        "\n",
        "current_n = 0 # Current number\n",
        "image_i = 0 # Current frame index\n",
        "for nt in range(number_transitions):\n",
        "  last_n = current_n\n",
        "  # Chose a different number randomly\n",
        "  while current_n == last_n:\n",
        "    current_n = np.random.random_integers(0, 9)\n",
        "  # Do a transition to this new number\n",
        "  for ntf in range(number_transition_frames): # For each transition frame\n",
        "    progress = ntf/number_transition_frames # Compute the transition progress\n",
        "    progress = (np.tanh(10*(progress-0.5))+1)/2 # Curve the transition (ease in - ease out)\n",
        "    images_ohe[image_i, last_n%10] = 1 - progress # Add the value for the current number in the OHE vector of the frame\n",
        "    images_ohe[image_i, current_n%10] = progress # Add the value for the next number in the OHE vector of the frame\n",
        "    images_var[image_i] = (np.cos(image_i/variation_transition_frames*np.pi)+1)/2 # Add the variation parameter (cosinusoide curve from 0 to 1 and 1 to 0)\n",
        "    image_i+=1\n",
        "\n",
        "images = decoder.predict([images_ohe, images_var]) # Decode each frame with the decoder\n",
        "\n",
        "# 2. Create the video\n",
        "# Create an information header\n",
        "header_height = 32\n",
        "bar_height = 6\n",
        "space = 8\n",
        "frame_size = 512\n",
        "# Create the video file\n",
        "video_name = 'results/RandomTransformations.mp4' # Video path\n",
        "video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), 25, (frame_size,frame_size+header_height))\n",
        "\n",
        "for f in range(total_frames): # For each frame\n",
        "  im = np.zeros((28, 28, 3)) # Create the number image matrix\n",
        "  # Draw the image in the matrix\n",
        "  im[:,:, 0] = images[f]*255\n",
        "  im[:,:, 1] = images[f]*255\n",
        "  im[:,:, 2] = images[f]*255\n",
        "  # Create the frame matrix\n",
        "  out = np.zeros((frame_size+header_height,frame_size, 3))\n",
        "  # Resize the number image\n",
        "  resized = cv2.resize(im, (frame_size, frame_size), fx=0,fy=0, interpolation = cv2.INTER_LINEAR)\n",
        "  # Fill the frame with the image\n",
        "  out[header_height:, :, :] = resized\n",
        "  # Add the information header\n",
        "  max_y = lambda x: space + int((x)*(frame_size - space*2))\n",
        "  var_max_y = max_y(images_var[f])\n",
        "  num_max_y = max_y(sum(images_ohe[f]*[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])/9)\n",
        "  out[space:space+bar_height, space:var_max_y, 0] = 255\n",
        "  out[2*space+bar_height:2*space+2*bar_height, space:num_max_y, 2] = 255\n",
        "  # Write the frame\n",
        "  video.write(out.astype('uint8'))\n",
        "# Save the video\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### IMAGE - Transformation between ordered numbers VS variation transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "id": "o_YVDwemuKMe"
      },
      "outputs": [],
      "source": [
        "# 1. Generate the images\n",
        "# Image parameters\n",
        "col = 64\n",
        "row = 64\n",
        "nb_of_var = col*row\n",
        "# Generate the images\n",
        "images_ohe = np.zeros((nb_of_var, 10))\n",
        "images_var = np.zeros((nb_of_var, 1))\n",
        "for i in range(nb_of_var):\n",
        "  images_var[i] = (i/row)%1 # Compute the variation parameter for each number (0 to 1 from the top to the bottom of the image)\n",
        "\n",
        "for r in range(row): # For each row\n",
        "  for c in range(col): # For each column\n",
        "    progress = c/col * 10.0 # At what number we are, from 0 to 9\n",
        "    n = int(progress) # Compute the actual integer\n",
        "    image_i = c*row + r # Compute the image index\n",
        "    images_ohe[image_i, n%10] = 1 - (progress - n) # Compute the OHE participation for n\n",
        "    images_ohe[image_i, (n+1)%10] = (progress - n) # Compute the OHE participation for n+1\n",
        "\n",
        "images = decoder.predict([images_ohe, images_var]) # Use the decoder to generate the images\n",
        "images = images.reshape((col, row, 28, 28)) # Reshape the images imatrix\n",
        "\n",
        "# 2. Plot the images\n",
        "im = np.zeros((28*row, 28*col)) # Initialize the matrix\n",
        "for c in range(col): # For each column\n",
        "  for r in range(row): # For each row\n",
        "    im[r*28:r*28+28,c*28:c*28+28] = images[c, r] # Add the image at the right position\n",
        "# Show and save the figure\n",
        "plt.rcParams[\"figure.figsize\"] = (col,row)\n",
        "plt.imshow(im, cmap = \"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.savefig(f'out.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "AE_CNNv2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "572328b00bfd6fc87186a5fc584bb026918b4fbba71251f50cf9866047be89a9"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('MLFenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
